# MIT MicroMasters in Statistics and Data Science
#### MIT Micro programme de deuxieme cycle (micro maitrise)

profile: 

## FAQ

https://micromasters.mit.edu/ds/faq/

## Details
The MITx MicroMasters Credential in Statistics and Data Science is a stand-alone certification program offered by MITx that is designed and administered by the MIT Institute for Data, Systems, and Society (IDSS) and supported by the MIT Office of Digital Learning (ODL).

The MITx MicroMasters credential consists of four intensive online courses providing learners with both the foundational knowledge essential to understand the methods and tools used in data science and with hands-on practice implementing and experimenting with data analysis techniques and machine learning algorithms. Along with these four courses is one virtually-proctored capstone exam.

There are four online courses and a capstone exam required to complete the MITx MicroMasters credential in Statistics and Data Science.

- 6.431x Probability - The Science of Uncertainty and Data
- 14.310x/14.310Fx- Data Analysis in Social Science
- 18.6501x Fundamentals of Statistics
- 6.86x Machine Learning with Python: from Linear Models to Deep Learning
- capstone / exam

note that business, marketing, psychology, etc are social sciences.

## Recommandations
We strongly recommend the completion of “Multivariable Calculus” on MIT OpenCourseWare before starting any of the MITx MicroMasters credential in Statistics and Data Science courses.

To succeed in the program, learners are strongly recommended to complete coursework from Introduction to Computer Science and Programming in Python (6.0001) or if possible: Introduction to Computational Thinking and Data Science (6.0002).

These courses build on one another. We encourage you to take them in this order:

## Details
What are the key concepts covered in each course?   ¶
6.431x (Probability - The Science of Uncertainty and Data) is an introduction to probabilistic models, including random processes and the basic elements of statistical inference, and covers the foundations of data science.

14.310x (Data Analysis in Social Science) covers the methods for harnessing and analyzing data to answer questions of cultural, social, economic, and policy interest.

18.6501x (Fundamentals of Statistics) helps learners to develop a deep understanding of the principles that underpin statistical inference: estimation, hypothesis testing, and prediction.


6.86x (Machine Learning with Python) is an in-depth introduction to the field of machine learning, from linear models to deep learning and reinforcement learning, with hands-on Python projects.
- 6.431x Probability - The Science of Uncertainty and Data (Introduction to Probability)
- 14.310x (Data Analysis in Social Science)
- 18.6501x (Fundamentals of Statistics)
- 6.86x (Machine Learning with Python)

At your discretion, to finish in a reduced time, 14.310x (Data Analysis in Social Science) may be taken in conjunction with either 18.6501x (Fundamentals of Statistics) or 6.86x (Machine Learning with Python) as a standalone class.


Python will be used in 6.686x, and R is covered in 18.6501x. Please note, it is assumed learners are comfortable with Python before starting this MicroMasters program. R will be reviewed.

-------------------------------------------------------------------------------------------------------

6.431x Fall 2018 Syllabus

Unit 0: Overview (released Tue. August 28)

Unit 1: Probability models and axioms (released Mon. Sep 3; Sections 1.1-1.2)

L1: Probability models and axioms

Problem Set 1 due on Tue Sept 11

Unit 2: Conditioning and independence (released Mon. Sept 10; Sections 1.3-1.5)

L2: Conditioning and Bayes' rule

L3: Independence

Problem Set 2 due on Tue Sept 18

Unit 3: Counting (released Mon. Sept 17; Section 1.6)

L4: Counting

Problem Set 3 due on Tue Sept 25

Unit 4: Discrete random variables (released Wed. Sept 19; Sections 2.1-2.7)

L5: Probability mass functions and expectations

L6: Variance; Conditioning on an event; Multiple r.v.'s

L7: Conditioning on a random variable; Independence of r.v.'s

Problem Set 4 due on Tue Oct 2

Exam 1 (Timed) : Covers material from L1 to L7 (released Wed. Oct 3; due on Tue. Oct 9)

Unit 5: Continuous random variables (released Mon. Oct 1; Sections 3.1-3.5)

L8: Probability density functions

L9: Conditioning on an event; Multiple r.v.'s

L10: Conditioning on a random variable; Independence; Bayes' rule

Problem Set 5 due on Tue. Oct 16

Unit 6: Further topics on random variables (released Mon. Oct 15; Sections 4.1-4.3, 4.5)

L11: Derived distributions

L12: Sums of r.v.'s; Covariance and correlation

L13: Conditional expectation and variance revisited; Sum of a random number of r.v.'s

Problem Set 6 due on Tue. Oct 23

Unit 7: Bayesian inference (released Mon. Oct 22 Sections 3.6, 8.1-8.4)

L14: Introduction to Bayesian inference

L15: Linear models with normal noise

L16: Least mean squares (LMS) estimation

L17: Linear least mean squares (LLMS) estimation

Problem Set 7a due on Tue. Oct 30

Problem Set 7b due on Tue. Nov 6

Exam 2 (Timed): Covers material from L8 to L17 (released Wed. Nov 1; due on Nov 13)

Unit 8: Limit theorems and classical statistics (released Mon. Nov 5; Sections 5.1-5.4, pp. 466-475)

L18: Inequalities, convergence, and the Weak Law of Large Numbers

L19: The Central Limit Theorem (CLT)

L20: An introduction to classical statistics

Problem Set 8 due on Tue. Nov 27

Unit 9: Bernoulli and Poisson processes (released Tue. Nov 14; Sections 6.1-6-2)

L21: The Bernoulli process

L22: The Poisson process

L23: More on the Poisson process

Problem Set 9 due on Tue. Dec 4

Unit 10: Markov chains (released Tue. Nov 26; Sections 7.1-7-4)

L24: Finite-state Markov chains

L25: Steady-state behavior of Markov chains

L26: Absorption probabilities and expected time to absorption

Problem Set 10 due on Tue. Dec 11

Final Exam (Timed) (released Wed. Dec 12; due on Sun. Dec 23) 
